{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWZvRkLf0ycx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "MeyiXK4mL4Rl",
    "outputId": "f178dc0a-83af-4cf0-cd9c-bba86e5e624d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K     |████████████████████████████████| 109.2MB 91kB/s \n",
      "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 64.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 74.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (46.0.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 2.2.0\n",
      "    Uninstalling tensorboard-2.2.0:\n",
      "      Successfully uninstalled tensorboard-2.2.0\n",
      "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
      "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
      "  Found existing installation: tensorflow 2.2.0rc2\n",
      "    Uninstalling tensorflow-2.2.0rc2:\n",
      "      Successfully uninstalled tensorflow-2.2.0rc2\n",
      "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "2Hf77nTm-cCf",
    "outputId": "599712cb-f11f-4f6a-ea9f-99f9e2615b1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
      "You set: `1.14`. This will be interpreted as: `1.x`.\n",
      "\n",
      "\n",
      "TensorFlow 1.x selected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.14\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "7RLzIQKxMpKS",
    "outputId": "aa7811e9-05c4-4f9d-f09e-cd9049ecea89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n",
      "2.2.5\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwEjbJEl-fqK"
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-Pm_dDjBFs7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTzHA5ul1VVc"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uoIIbJYR1ZQz"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rFt6tqD26Ih"
   },
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nqa4MbMy1l2E"
   },
   "outputs": [],
   "source": [
    "#unzipping the cb6133 filtered file\n",
    "with zipfile.ZipFile(\"drive/My Drive/Major Project/cullpdb+profile_6133_filtered.npy.gz.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"drive/My Drive/Major Project/cullpdb+profile_6133_filtered.npy.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvGUSdK61d7t"
   },
   "outputs": [],
   "source": [
    "#unzipping the cb6133 file\n",
    "with zipfile.ZipFile(\"drive/My Drive/Major Project/cullpdb+profile_6133.npy.gz.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"drive/My Drive/Major Project/cullpdb+profile_6133.npy.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OBZDtIJT3Nsa"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqWIVfLv3KZh"
   },
   "outputs": [],
   "source": [
    "def preprocess(npy_file, max_len):\n",
    "    \n",
    "    data = np.load(npy_file)\n",
    "    \n",
    "    residue_list = ['A', 'C', 'E', 'D', 'G', 'F', 'I', 'H', 'K', 'M', 'L', 'N', 'Q', 'P', 'S', 'R', 'T', 'W', 'V', 'Y', \n",
    "                    'X', 'NoSeq']\n",
    "    q8_list = ['L', 'B', 'E', 'G', 'I', 'H', 'S', 'T','NoSeq']\n",
    "    \n",
    "    data = data.reshape(data.shape[0], 700, -1)\n",
    "    \n",
    "    residue_onehot = data[:,:,0:22]\n",
    "    q8_onehot = data[:,:,22:31]\n",
    "    nc_terminal = data[:,:,31:33]\n",
    "    profile = data[:,:,35:57]\n",
    "    \n",
    "    zero_arr = np.zeros((profile.shape[0], max_len - profile.shape[1], profile.shape[2]))\n",
    "    profile_padded = np.concatenate([profile, zero_arr], axis=1)\n",
    "    \n",
    "    residue_str = np.array(residue_list)[residue_onehot.argmax(2)]\n",
    "    q8_str = np.array(q8_list)[q8_onehot.argmax(2)]\n",
    "    \n",
    "    residue_array = []\n",
    "    for vec in residue_str:\n",
    "        x = ''.join(vec[vec!='NoSeq'])\n",
    "        residue_array.append(x)\n",
    "        \n",
    "    \n",
    "    q8_array = []\n",
    "    for vec in q8_str:\n",
    "        x = ''.join(vec[vec!='NoSeq'])\n",
    "        q8_array.append(x)\n",
    "    \n",
    "    id_list = np.arange(1, len(q8_array) + 1)\n",
    "    len_list = np.array([len(x) for x in residue_array])\n",
    "    \n",
    "    protein_dataset = pd.DataFrame({'id': id_list, 'len': len_list, 'primary structure': residue_array, \n",
    "                                    'secondary structure': q8_array})\n",
    "        \n",
    "    return protein_dataset, profile_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rVcEdO8h3clq"
   },
   "outputs": [],
   "source": [
    "cb6133, cb6133_profile = preprocess(\"drive/My Drive/Major Project/cullpdb+profile_6133.npy.gz/cullpdb+profile_6133.npy.gz\", 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SarPS73h3nwd"
   },
   "outputs": [],
   "source": [
    "cb6133_filtered, cb6133_filtered_profile = preprocess(\"drive/My Drive/Major Project/cullpdb+profile_6133_filtered.npy.gz/cullpdb+profile_6133_filtered.npy.gz\", 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpYHZnI44JWA"
   },
   "outputs": [],
   "source": [
    "cb513, cb513_profile = preprocess(\"drive/My Drive/Major Project/cb513+profile_split1.npy.gz\", 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yl1NJt164ZFl"
   },
   "outputs": [],
   "source": [
    "cb6133_profile_shape = cb6133_profile.reshape(cb6133_profile.shape[0], 700*22)\n",
    "cb6133_filtered_profile_shape = cb6133_filtered_profile.reshape(cb6133_filtered.shape[0], 700*22)\n",
    "cb513_profile_shape = cb513_profile.reshape(cb513_profile.shape[0], 700*22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCh7QO374daQ"
   },
   "source": [
    "## Let us make csv file of cb6133, cb6133_filtered and cb513 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "m43zPLVz8FhO",
    "outputId": "ce9b99f6-e65d-449a-c836-56db18e80105"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b5b4efc8d056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcb6133_profile_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb6133_profile_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcb6133_filtered_profile_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb6133_filtered_profile_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcb513_profile_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb513_profile_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cb6133_profile_shape' is not defined"
     ]
    }
   ],
   "source": [
    "cb6133_profile_df = pd.DataFrame(cb6133_profile_shape)\n",
    "cb6133_filtered_profile_df = pd.DataFrame(cb6133_filtered_profile_shape)\n",
    "cb513_profile_df = pd.DataFrame(cb513_profile_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7f2GMLRU4ay2"
   },
   "outputs": [],
   "source": [
    "cb6133_csv = cb6133.to_csv(\"drive/My Drive/Major Project/cb6133.csv\", sep=\",\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y1LPwWpm5faA"
   },
   "outputs": [],
   "source": [
    "cb6133_profile_csv = cb6133_profile_df.to_csv(\"drive/My Drive/Major Project/cb6133_profile.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CF81F6y06jQX"
   },
   "outputs": [],
   "source": [
    "cb6133_filtered_csv = cb6133_filtered.to_csv(\"drive/My Drive/Major Project/cb6133_filtered.csv\", sep=\",\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLjVBZR37H-j"
   },
   "outputs": [],
   "source": [
    "cb6133_filtered_profile_csv = cb6133_filtered_profile_df.to_csv(\"drive/My Drive/Major Project/cb6133_filtered_profile.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-bQn3HJ75Qs"
   },
   "outputs": [],
   "source": [
    "cb513_csv = cb513.to_csv(\"drive/My Drive/Major Project/cb513.csv\", sep=\",\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOIKqm0n8DX7"
   },
   "outputs": [],
   "source": [
    "cb513_profile_csv = cb513_profile_df.to_csv(\"drive/My Drive/Major Project/cb513_profile.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9ryGYrP8xG-"
   },
   "source": [
    "## Splitting the dataset into training, testing and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53-L2np58fOX"
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = cb6133_filtered, cb6133[5877:6133], cb513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9L0vzcyO9CiB"
   },
   "outputs": [],
   "source": [
    "train_profile_df, val_profile_df, test_profile_df = cb6133_filtered_profile, cb6133_profile[5877:6133], cb513_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okhaLrMY9G1X"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_df[['primary structure', 'secondary structure']][(train_df.len <= 700)].values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAXvrLRX9KQh"
   },
   "outputs": [],
   "source": [
    "X_val, y_val = val_df[['primary structure', 'secondary structure']][(val_df.len <= 700)].values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QRnEx1a9M5O"
   },
   "outputs": [],
   "source": [
    "X_test, y_test = test_df[['primary structure', 'secondary structure']][(test_df.len <= 700)].values.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mqo6IO39Q96"
   },
   "source": [
    "## Converting text to integers i.e tokenizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UuYc_PJ9OhE"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jn4ZnDHd9at-"
   },
   "outputs": [],
   "source": [
    "X_train_tokenizer = Tokenizer(char_level=True)\n",
    "X_train_tokenizer.fit_on_texts(X_train)\n",
    "X_train_seqs = X_train_tokenizer.texts_to_sequences(X_train)\n",
    "X_train = sequence.pad_sequences(X_train_seqs, padding=\"post\", maxlen=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hu0Bzwl19clG"
   },
   "outputs": [],
   "source": [
    "X_val_tokenizer = Tokenizer(char_level=True)\n",
    "X_val_tokenizer.fit_on_texts(X_val)\n",
    "X_val_seqs = X_val_tokenizer.texts_to_sequences(X_val)\n",
    "X_val = sequence.pad_sequences(X_val_seqs, padding=\"post\", maxlen=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2vjr1vZC9ezg"
   },
   "outputs": [],
   "source": [
    "X_test_tokenizer = Tokenizer(char_level=True)\n",
    "X_test_tokenizer.fit_on_texts(X_test)\n",
    "X_test_seqs = X_test_tokenizer.texts_to_sequences(X_test)\n",
    "X_test = sequence.pad_sequences(X_test_seqs, padding=\"post\", maxlen=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-m2d8TF9gWr"
   },
   "outputs": [],
   "source": [
    "y_train_tokenizer = Tokenizer(char_level = True)\n",
    "y_train_tokenizer.fit_on_texts(y_train)\n",
    "y_train_seqs = y_train_tokenizer.texts_to_sequences(y_train)\n",
    "y_train = sequence.pad_sequences(y_train_seqs, padding=\"post\", maxlen=700)\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whmomhuK948I"
   },
   "outputs": [],
   "source": [
    "y_val_tokenizer = Tokenizer(char_level=True)\n",
    "y_val_tokenizer.fit_on_texts(y_val)\n",
    "y_val_seqs = y_val_tokenizer.texts_to_sequences(y_val)\n",
    "y_val = sequence.pad_sequences(y_val_seqs, padding=\"post\", maxlen=700)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhHKYx4p965-"
   },
   "outputs": [],
   "source": [
    "y_test_tokenizer = Tokenizer(char_level=True)\n",
    "y_test_tokenizer.fit_on_texts(y_test)\n",
    "y_test_seqs = y_test_tokenizer.texts_to_sequences(y_test)\n",
    "y_test = sequence.pad_sequences(y_test_seqs, padding=\"post\", maxlen=700)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "daEE3cJOpCwN",
    "outputId": "5c2ad1c2-4355-43bf-fc29-05a619a2c6e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5534, 700, 9)"
      ]
     },
     "execution_count": 236,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3b84oT0-98XO"
   },
   "outputs": [],
   "source": [
    "x_word_index = len(X_train_tokenizer.word_index) + 1\n",
    "y_word_index = len(y_train_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HP7W5fF-AGZ"
   },
   "source": [
    "## Training the model saving weights into the format of .hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AWZ8Ml1ENTa3"
   },
   "outputs": [],
   "source": [
    "from keras.models import Input, Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, LSTM, Bidirectional, dot, concatenate\n",
    "from keras.layers import TimeDistributed, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEdNa4MaeYBY"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "iXilK94x-IOU",
    "outputId": "5e9ecd5f-81c8-4eb5-ed70-75ed6163bee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(700,))\n",
    "input2 = Input(shape=(700, 22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "wMfPGstFeD6M",
    "outputId": "3c9529bd-907c-4725-f7ec-a7bfff88ef94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input_embedd = Embedding(input_dim = x_word_index, output_dim = 128, input_length = 700)(input1)\n",
    "input_embedding = concatenate([input_embedd, input2], axis = 2)\n",
    "\n",
    "conv1d_1 = Conv1D(64, 17, strides = 1, padding=\"same\")(input_embedding)\n",
    "conv1d_2 = Conv1D(64, 15, strides = 1, padding=\"same\")(input_embedding)\n",
    "conv1d_inner_concat_1 = concatenate([input_embedding, conv1d_1], axis = 2)\n",
    "conv1d_concat_1 = concatenate([conv1d_inner_concat_1, conv1d_2], axis = 2)\n",
    "\n",
    "conv1d_3 = Conv1D(64, 11, strides = 1, padding=\"same\")(conv1d_concat_1)\n",
    "conv1d_4 = Conv1D(64, 7, strides = 1, padding=\"same\")(conv1d_concat_1)\n",
    "conv1d_inner_concat_2 = concatenate([conv1d_concat_1, conv1d_3], axis = 2)\n",
    "conv1d_concat_2 = concatenate([conv1d_inner_concat_2, conv1d_4], axis = 2)\n",
    "\n",
    "conv1d_5 = Conv1D(64, 5, strides = 1, padding=\"same\")(conv1d_concat_2)\n",
    "conv1d_6 = Conv1D(64, 2, strides = 1, padding=\"same\")(conv1d_concat_2)\n",
    "conv1d_inner_concat_3 = concatenate([conv1d_concat_2, conv1d_5], axis = 2)\n",
    "conv1d_concat_3 = concatenate([conv1d_inner_concat_3, conv1d_6], axis = 2)\n",
    "\n",
    "lstm_1 = LSTM(64, return_sequences=True, activation='tanh', recurrent_activation='sigmoid', use_bias = True,\n",
    "              dropout = 0.3, recurrent_dropout = 0.1, implementation = 1)(input_embedding)\n",
    "lstm_2 = LSTM(64, return_sequences=True, activation='tanh', recurrent_activation='sigmoid', use_bias=True,\n",
    "             dropout = 0.3, recurrent_dropout = 0.1, implementation = 1)(lstm_1)\n",
    "lstm_3 = LSTM(64, return_sequences=True, activation='tanh', recurrent_activation='sigmoid', use_bias=True,\n",
    "             dropout = 0.3, recurrent_dropout = 0.1, implementation = 1)(lstm_2)\n",
    "\n",
    "dot_1 = dot([lstm_3, conv1d_concat_3], axes=[1,1])\n",
    "dot_1 = Activation(\"softmax\")(dot_1)\n",
    "context = dot([conv1d_concat_3, dot_1], axes=[2,2])\n",
    "lstm_conv1d_concat = concatenate([context, conv1d_concat_3])\n",
    "\n",
    "bilstm_1 = Bidirectional(LSTM(64, return_sequences=True, activation='tanh', recurrent_activation='sigmoid', use_bias = True, \n",
    "                              dropout = 0.2, implementation = 1), merge_mode='concat')(lstm_conv1d_concat)\n",
    "bilstm_2 = Bidirectional(LSTM(64, return_sequences=True, activation='tanh', recurrent_activation='sigmoid', use_bias=True,\n",
    "                             dropout = 0.2, implementation = 1), merge_mode='concat')(bilstm_1)\n",
    "\n",
    "dense_1 = TimeDistributed(Dense(150, activation='relu'))(bilstm_2)\n",
    "dense_2 = TimeDistributed(Dense(75, activation='relu'))(dense_1)\n",
    "output_dense = TimeDistributed(Dense(y_word_index, activation='softmax'))(dense_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z9gl-EM_-LGS"
   },
   "outputs": [],
   "source": [
    "model = Model([input1, input2], output_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "Bm1Ya3uG-MuV",
    "outputId": "46618feb-e392-4ef9-cc6f-a17721e81327"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgyfmN8K-QvI"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjjXqLhF_567"
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(\"drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\", monitor='val_loss', \n",
    "                            save_best_only = True, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "g-KYdJcSCHVe",
    "outputId": "27d1c39b-0285-4b6e-ea6f-c8343ed36243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 5534 samples, validate on 256 samples\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "5534/5534 [==============================] - 538s 97ms/step - loss: 0.5519 - acc: 0.7880 - val_loss: 0.4842 - val_acc: 0.8084\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48419, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 2/60\n",
      "5534/5534 [==============================] - 520s 94ms/step - loss: 0.5099 - acc: 0.8000 - val_loss: 0.4814 - val_acc: 0.8087\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.48419 to 0.48138, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 3/60\n",
      "5534/5534 [==============================] - 518s 94ms/step - loss: 0.4667 - acc: 0.8177 - val_loss: 0.4023 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.48138 to 0.40231, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 4/60\n",
      "5534/5534 [==============================] - 508s 92ms/step - loss: 0.3912 - acc: 0.8569 - val_loss: 0.3311 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.40231 to 0.33107, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 5/60\n",
      "5534/5534 [==============================] - 503s 91ms/step - loss: 0.3857 - acc: 0.8682 - val_loss: 0.3406 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.33107\n",
      "Epoch 6/60\n",
      "5534/5534 [==============================] - 499s 90ms/step - loss: 0.3425 - acc: 0.8760 - val_loss: 0.3053 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33107 to 0.30532, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 7/60\n",
      "5534/5534 [==============================] - 497s 90ms/step - loss: 0.3279 - acc: 0.8814 - val_loss: 0.2992 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.30532 to 0.29920, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 8/60\n",
      "5534/5534 [==============================] - 497s 90ms/step - loss: 0.3166 - acc: 0.8861 - val_loss: 0.2979 - val_acc: 0.8921\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.29920 to 0.29793, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 9/60\n",
      "5534/5534 [==============================] - 493s 89ms/step - loss: 0.3019 - acc: 0.8910 - val_loss: 0.2765 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.29793 to 0.27653, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 10/60\n",
      "5534/5534 [==============================] - 492s 89ms/step - loss: 0.2928 - acc: 0.8942 - val_loss: 0.2832 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27653\n",
      "Epoch 11/60\n",
      "5534/5534 [==============================] - 491s 89ms/step - loss: 0.2879 - acc: 0.8960 - val_loss: 0.2757 - val_acc: 0.9002\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.27653 to 0.27567, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 12/60\n",
      "5534/5534 [==============================] - 491s 89ms/step - loss: 0.2809 - acc: 0.8983 - val_loss: 0.2655 - val_acc: 0.9035\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.27567 to 0.26549, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 13/60\n",
      "5534/5534 [==============================] - 490s 89ms/step - loss: 0.2775 - acc: 0.8992 - val_loss: 0.2613 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.26549 to 0.26127, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 14/60\n",
      "5534/5534 [==============================] - 490s 89ms/step - loss: 0.2755 - acc: 0.9001 - val_loss: 0.2780 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26127\n",
      "Epoch 15/60\n",
      "5534/5534 [==============================] - 489s 88ms/step - loss: 0.2722 - acc: 0.9012 - val_loss: 0.2552 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26127 to 0.25519, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 16/60\n",
      "5534/5534 [==============================] - 488s 88ms/step - loss: 0.3306 - acc: 0.8957 - val_loss: 0.2575 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.25519\n",
      "Epoch 17/60\n",
      "5534/5534 [==============================] - 488s 88ms/step - loss: 0.2690 - acc: 0.9023 - val_loss: 0.2517 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25519 to 0.25174, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 18/60\n",
      "5534/5534 [==============================] - 488s 88ms/step - loss: 0.2702 - acc: 0.9027 - val_loss: 0.2676 - val_acc: 0.9019\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.25174\n",
      "Epoch 19/60\n",
      "5534/5534 [==============================] - 487s 88ms/step - loss: 0.2709 - acc: 0.9019 - val_loss: 0.2618 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.25174\n",
      "Epoch 20/60\n",
      "5534/5534 [==============================] - 488s 88ms/step - loss: 0.2661 - acc: 0.9031 - val_loss: 0.2481 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.25174 to 0.24813, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 21/60\n",
      "5534/5534 [==============================] - 489s 88ms/step - loss: 0.2611 - acc: 0.9047 - val_loss: 0.2449 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.24813 to 0.24493, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 22/60\n",
      "5534/5534 [==============================] - 488s 88ms/step - loss: 0.2618 - acc: 0.9045 - val_loss: 0.2441 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.24493 to 0.24414, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 23/60\n",
      "5534/5534 [==============================] - 488s 88ms/step - loss: 0.2590 - acc: 0.9056 - val_loss: 0.2432 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.24414 to 0.24317, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 24/60\n",
      "5534/5534 [==============================] - 489s 88ms/step - loss: 0.2577 - acc: 0.9058 - val_loss: 0.2423 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.24317 to 0.24227, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 25/60\n",
      "5534/5534 [==============================] - 488s 88ms/step - loss: 0.2569 - acc: 0.9063 - val_loss: 0.2430 - val_acc: 0.9112\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.24227\n",
      "Epoch 26/60\n",
      "5534/5534 [==============================] - 488s 88ms/step - loss: 0.2549 - acc: 0.9067 - val_loss: 0.2445 - val_acc: 0.9101\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.24227\n",
      "Epoch 27/60\n",
      "5534/5534 [==============================] - 489s 88ms/step - loss: 0.2536 - acc: 0.9074 - val_loss: 0.2572 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.24227\n",
      "Epoch 28/60\n",
      "5534/5534 [==============================] - 489s 88ms/step - loss: 0.2526 - acc: 0.9076 - val_loss: 0.2387 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.24227 to 0.23868, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 29/60\n",
      "5534/5534 [==============================] - 490s 89ms/step - loss: 0.2516 - acc: 0.9081 - val_loss: 0.2384 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.23868 to 0.23838, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 30/60\n",
      "5534/5534 [==============================] - 490s 89ms/step - loss: 0.2524 - acc: 0.9087 - val_loss: 0.2441 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.23838\n",
      "Epoch 31/60\n",
      "5534/5534 [==============================] - 489s 88ms/step - loss: 0.2497 - acc: 0.9086 - val_loss: 0.2462 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.23838\n",
      "Epoch 32/60\n",
      "5534/5534 [==============================] - 489s 88ms/step - loss: 0.2489 - acc: 0.9089 - val_loss: 0.2369 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.23838 to 0.23693, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 33/60\n",
      "5534/5534 [==============================] - 490s 88ms/step - loss: 0.2486 - acc: 0.9094 - val_loss: 0.2402 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.23693\n",
      "Epoch 34/60\n",
      "5534/5534 [==============================] - 490s 89ms/step - loss: 0.2468 - acc: 0.9096 - val_loss: 0.2386 - val_acc: 0.9118\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.23693\n",
      "Epoch 35/60\n",
      "5534/5534 [==============================] - 490s 89ms/step - loss: 0.2490 - acc: 0.9094 - val_loss: 0.2334 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.23693 to 0.23342, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 36/60\n",
      "5534/5534 [==============================] - 491s 89ms/step - loss: 0.2451 - acc: 0.9103 - val_loss: 0.2328 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.23342 to 0.23284, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 37/60\n",
      "5534/5534 [==============================] - 491s 89ms/step - loss: 0.2468 - acc: 0.9097 - val_loss: 0.2350 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.23284\n",
      "Epoch 38/60\n",
      "5534/5534 [==============================] - 491s 89ms/step - loss: 0.2458 - acc: 0.9100 - val_loss: 0.2390 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.23284\n",
      "Epoch 39/60\n",
      "5534/5534 [==============================] - 493s 89ms/step - loss: 0.2453 - acc: 0.9104 - val_loss: 0.2330 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.23284\n",
      "Epoch 40/60\n",
      "5534/5534 [==============================] - 491s 89ms/step - loss: 0.2444 - acc: 0.9106 - val_loss: 0.2307 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.23284 to 0.23066, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 41/60\n",
      "5534/5534 [==============================] - 492s 89ms/step - loss: 0.2453 - acc: 0.9103 - val_loss: 0.2307 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.23066\n",
      "Epoch 42/60\n",
      "5534/5534 [==============================] - 495s 89ms/step - loss: 0.2433 - acc: 0.9108 - val_loss: 0.2322 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.23066\n",
      "Epoch 43/60\n",
      "5534/5534 [==============================] - 494s 89ms/step - loss: 0.2426 - acc: 0.9111 - val_loss: 0.2304 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.23066 to 0.23042, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 44/60\n",
      "5534/5534 [==============================] - 492s 89ms/step - loss: 0.2576 - acc: 0.9102 - val_loss: 0.2321 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.23042\n",
      "Epoch 45/60\n",
      "5534/5534 [==============================] - 493s 89ms/step - loss: 0.2413 - acc: 0.9118 - val_loss: 0.2294 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.23042 to 0.22939, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 46/60\n",
      "5534/5534 [==============================] - 492s 89ms/step - loss: 0.2407 - acc: 0.9119 - val_loss: 0.2292 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.22939 to 0.22919, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 47/60\n",
      "5534/5534 [==============================] - 490s 89ms/step - loss: 0.2393 - acc: 0.9123 - val_loss: 0.2279 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.22919 to 0.22788, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 48/60\n",
      "5534/5534 [==============================] - 491s 89ms/step - loss: 0.2391 - acc: 0.9123 - val_loss: 0.2273 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.22788 to 0.22728, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 49/60\n",
      "5534/5534 [==============================] - 491s 89ms/step - loss: 0.2384 - acc: 0.9126 - val_loss: 0.2297 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.22728\n",
      "Epoch 50/60\n",
      "5534/5534 [==============================] - 491s 89ms/step - loss: 0.2505 - acc: 0.9116 - val_loss: 0.2269 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.22728 to 0.22693, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 51/60\n",
      "5534/5534 [==============================] - 492s 89ms/step - loss: 0.2376 - acc: 0.9128 - val_loss: 0.2322 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.22693\n",
      "Epoch 52/60\n",
      "5534/5534 [==============================] - 493s 89ms/step - loss: 0.2376 - acc: 0.9128 - val_loss: 0.2287 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.22693\n",
      "Epoch 53/60\n",
      "5534/5534 [==============================] - 493s 89ms/step - loss: 0.2367 - acc: 0.9132 - val_loss: 0.2253 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.22693 to 0.22531, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 54/60\n",
      "5534/5534 [==============================] - 493s 89ms/step - loss: 0.2360 - acc: 0.9135 - val_loss: 0.2230 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.22531 to 0.22297, saving model to drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\n",
      "Epoch 55/60\n",
      "5534/5534 [==============================] - 493s 89ms/step - loss: 0.2363 - acc: 0.9136 - val_loss: 0.2241 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.22297\n",
      "Epoch 56/60\n",
      "5534/5534 [==============================] - 491s 89ms/step - loss: 0.2346 - acc: 0.9141 - val_loss: 0.2309 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.22297\n",
      "Epoch 57/60\n",
      "4800/5534 [=========================>....] - ETA: 1:03 - loss: 0.2375 - acc: 0.9128"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit([X_train, train_profile_df], y_train, batch_size = 64, epochs = 60, validation_data = ([X_val, val_profile_df], y_val), \n",
    "                      callbacks = [checkpointer], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vY8ppoyy8hK2"
   },
   "outputs": [],
   "source": [
    "weights = model.load_weights(\"drive/My Drive/Major Project/weights.project_secondary_structure_tanh.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvKVE8vioy7A"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict([X_test, test_profile_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QLbiBgZTI0at"
   },
   "source": [
    "## For Single Input Amino Acid Prediction or in the form of FASTA Sequence\n",
    "## Useful for Web Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxiU0Kdd1AHk"
   },
   "outputs": [],
   "source": [
    "def amino_preprocess(amino_acid):\n",
    "\n",
    "    amino_acid_tokenize = Tokenizer(char_level = True)\n",
    "    amino_acid_tokenize.fit_on_texts(amino_acid)\n",
    "    amino_acid_seqs = amino_acid_tokenize.texts_to_sequences(amino_acid)\n",
    "    amino_acid_seqs = sequence.pad_sequences(amino_acid_seqs, padding=\"post\", maxlen=700)\n",
    "\n",
    "    return amino_acid_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Svd_f8tzl3aj"
   },
   "outputs": [],
   "source": [
    "def secondary_preprocess(secondary_sequence):\n",
    "\n",
    "    secondary_sequence_tokenize = Tokenizer(char_level = True)\n",
    "    secondary_sequence_tokenize.fit_on_texts(secondary_sequence)\n",
    "    secondary_sequence_seqs = secondary_sequence_tokenize.texts_to_sequences(secondary_sequence)\n",
    "    secondary_sequence_seqs = sequence.pad_sequences(secondary_sequence_seqs, padding=\"post\", maxlen=700)\n",
    "    secondary_sequence_seqs = to_categorical(secondary_sequence_seqs)\n",
    "\n",
    "    return secondary_sequence_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mwsG6SJeaC5s"
   },
   "outputs": [],
   "source": [
    "def string_sequence(predicted_sequence):\n",
    "\n",
    "    q8_list = ['L', 'B', 'E', 'G', 'I', 'H', 'S', 'T','NoSeq']\n",
    "\n",
    "    q8_str = np.array(q8_list)[predicted_sequence.argmax(2)]\n",
    "\n",
    "    predicted_list = []\n",
    "\n",
    "    for vec in q8_str:\n",
    "        x = ''.join(vec[vec!='NoSeq'])\n",
    "        predicted_list.append(x)\n",
    "\n",
    "    return predicted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SnQ1G1fsinGM"
   },
   "outputs": [],
   "source": [
    "amino_acid_sequence, secondary_acid_sequence = test_df[['primary structure', 'secondary structure']][test_df.len<=700].values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vsKQVtOV19kb",
    "outputId": "524ea582-b47c-43c4-e4a1-34f268d2eedb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "predict_preprocess = amino_preprocess(amino_acid_sequence)\n",
    "true_preprocess = secondary_preprocess(secondary_acid_sequence)\n",
    "print(true_preprocess.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WNrBL4oB_gVH",
    "outputId": "655a12e0-9b6e-474d-ff68-5121de1db923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 40s 77ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.evaluate([predict_preprocess, test_profile_df], true_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "nBylxc25BnNm",
    "outputId": "fe223e27-1bf9-4c20-f139-f1c891849768"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7afe4e74bf1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2Vz9wpyBsPy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Major Project 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
